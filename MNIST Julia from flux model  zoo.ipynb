{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m CuArrays ─ v1.7.2\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.3/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.3/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.3/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.3/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.3/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.3/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.3/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.3/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.add(\"BSON\")\n",
    "Pkg.add(\"Flux\")\n",
    "Pkg.add(\"Statistics\")\n",
    "Pkg.add(\"Printf\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "ename": "Pkg.Types.ResolverError",
     "evalue": "Unsatisfiable requirements detected for package CuArrays [3a865a2d]:\n CuArrays [3a865a2d] log:\n ├─possible versions are: [0.2.1, 0.3.0, 0.4.0, 0.5.0, 0.6.0-0.6.2, 0.7.0-0.7.3, 0.8.0-0.8.1, 0.9.0-0.9.1, 1.0.0-1.0.2, 1.1.0, 1.2.0-1.2.1, 1.3.0, 1.4.0-1.4.7, 1.5.0, 1.6.0, 1.7.0-1.7.2] or uninstalled\n ├─restricted to versions 1.3 by an explicit requirement, leaving only versions 1.3.0\n └─restricted by compatibility requirements with CUDAdrv [c5f51814] to versions: 1.7.1-1.7.2 or uninstalled — no versions left\n   └─CUDAdrv [c5f51814] log:\n     ├─possible versions are: [0.8.0-0.8.6, 0.9.0, 1.0.0-1.0.1, 2.0.0, 3.0.0-3.0.1, 3.1.0, 4.0.0-4.0.4, 5.0.0-5.0.1, 5.1.0, 6.0.0] or uninstalled\n     └─restricted to versions 6.0.0 by an explicit requirement, leaving only versions 6.0.0",
     "output_type": "error",
     "traceback": [
      "Unsatisfiable requirements detected for package CuArrays [3a865a2d]:\n CuArrays [3a865a2d] log:\n ├─possible versions are: [0.2.1, 0.3.0, 0.4.0, 0.5.0, 0.6.0-0.6.2, 0.7.0-0.7.3, 0.8.0-0.8.1, 0.9.0-0.9.1, 1.0.0-1.0.2, 1.1.0, 1.2.0-1.2.1, 1.3.0, 1.4.0-1.4.7, 1.5.0, 1.6.0, 1.7.0-1.7.2] or uninstalled\n ├─restricted to versions 1.3 by an explicit requirement, leaving only versions 1.3.0\n └─restricted by compatibility requirements with CUDAdrv [c5f51814] to versions: 1.7.1-1.7.2 or uninstalled — no versions left\n   └─CUDAdrv [c5f51814] log:\n     ├─possible versions are: [0.8.0-0.8.6, 0.9.0, 1.0.0-1.0.1, 2.0.0, 3.0.0-3.0.1, 3.1.0, 4.0.0-4.0.4, 5.0.0-5.0.1, 5.1.0, 6.0.0] or uninstalled\n     └─restricted to versions 6.0.0 by an explicit requirement, leaving only versions 6.0.0",
      "",
      "Stacktrace:",
      " [1] #propagate_constraints!#61(::Bool, ::typeof(Pkg.GraphType.propagate_constraints!), ::Pkg.GraphType.Graph, ::Set{Int64}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.3/Pkg/src/GraphType.jl:1007",
      " [2] propagate_constraints! at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.3/Pkg/src/GraphType.jl:948 [inlined]",
      " [3] #simplify_graph!#121(::Bool, ::typeof(Pkg.GraphType.simplify_graph!), ::Pkg.GraphType.Graph, ::Set{Int64}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.3/Pkg/src/GraphType.jl:1462",
      " [4] simplify_graph! at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.3/Pkg/src/GraphType.jl:1462 [inlined]",
      " [5] resolve_versions!(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.3/Pkg/src/Operations.jl:321",
      " [6] #add#112(::Bool, ::Pkg.BinaryPlatforms.Linux, ::typeof(Pkg.Operations.add), ::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}, ::Array{Base.UUID,1}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.3/Pkg/src/Operations.jl:1010",
      " [7] #add at ./none:0 [inlined]",
      " [8] #add#25(::Bool, ::Pkg.BinaryPlatforms.Linux, ::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::typeof(Pkg.API.add), ::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.3/Pkg/src/API.jl:102",
      " [9] add(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.3/Pkg/src/API.jl:72",
      " [10] #add#24 at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.3/Pkg/src/API.jl:69 [inlined]",
      " [11] add at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.3/Pkg/src/API.jl:69 [inlined]",
      " [12] #add#20 at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.3/Pkg/src/API.jl:66 [inlined]",
      " [13] add(::Pkg.Types.PackageSpec) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.3/Pkg/src/API.jl:66",
      " [14] top-level scope at In[2]:1"
     ]
    }
   ],
   "source": [
    "# If we don't do this, then flux won't grok GPUs\n",
    "# Pinning to 1.3 was suggested in https://github.com/FluxML/Flux.jl/issues/918\n",
    "Pkg.add(Pkg.PackageSpec(;name=\"CuArrays\", version=\"1.3\"))\n",
    "# Pkg.pin(\"CuArrays\", v\"1.3\")\n",
    "# Pkg.add(\"CuArrays\")\n",
    "using CuArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Loading data set\n",
      "└ @ Main In[3]:18\n",
      "┌ Info: Constructing model...\n",
      "└ @ Main In[3]:46\n",
      "┌ Info: Loading model...\n",
      "└ @ Main In[3]:69\n",
      "┌ Info: Precompiling model...\n",
      "└ @ Main In[3]:77\n",
      "┌ Info: Done precompiling model...\n",
      "└ @ Main In[3]:81\n",
      "┌ Info: Beginning training loop...\n",
      "└ @ Main In[3]:100\n",
      "┌ Info: [1]:Starting epoch\n",
      "└ @ Main In[3]:105\n",
      "┌ Info: [1]: Test accuracy: 0.9595\n",
      "└ @ Main In[3]:113\n",
      "┌ Info:  -> New best accuracy! Saving model out to mnist_conv.bson\n",
      "└ @ Main In[3]:123\n",
      "┌ Info: [2]:Starting epoch\n",
      "└ @ Main In[3]:105\n"
     ]
    }
   ],
   "source": [
    "# From\n",
    "#    https://github.com/FluxML/model-zoo/blob/master/vision/mnist/conv.jl\n",
    "# Classifies MNIST digits with a convolutional network.\n",
    "# Writes out saved model to the file \"mnist_conv.bson\".\n",
    "# Demonstrates basic model construction, training, saving,\n",
    "# conditional early-exit, and learning rate scheduling.\n",
    "#\n",
    "# This model, while simple, should hit around 99% test\n",
    "# accuracy after training for approximately 20 epochs.\n",
    "\n",
    "\n",
    "using Flux, Flux.Data.MNIST, Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated, partition\n",
    "using Printf, BSON\n",
    "\n",
    "# Load labels and images from Flux.Data.MNIST\n",
    "@info(\"Loading data set\")\n",
    "train_labels = MNIST.labels()\n",
    "train_imgs = MNIST.images()\n",
    "\n",
    "# Bundle images together with labels and group into minibatchess\n",
    "function make_minibatch(X, Y, idxs)\n",
    "    X_batch = Array{Float32}(undef, size(X[1])..., 1, length(idxs))\n",
    "    for i in 1:length(idxs)\n",
    "        X_batch[:, :, :, i] = Float32.(X[idxs[i]])\n",
    "    end\n",
    "    Y_batch = onehotbatch(Y[idxs], 0:9)\n",
    "    return (X_batch, Y_batch)\n",
    "end\n",
    "\n",
    "# batch_size = 128 (original) will cause out of memory error. Trying out\n",
    "# smaller batchsizes.\n",
    "batch_size = 32\n",
    "mb_idxs = partition(1:length(train_imgs), batch_size)\n",
    "train_set = [make_minibatch(train_imgs, train_labels, i) for i in mb_idxs]\n",
    "\n",
    "# Prepare test set as one giant minibatch:\n",
    "test_imgs = MNIST.images(:test)\n",
    "test_labels = MNIST.labels(:test)\n",
    "test_set = make_minibatch(test_imgs, test_labels, 1:length(test_imgs))\n",
    "\n",
    "# Define our model.  We will use a simple convolutional architecture with\n",
    "# three iterations of Conv -> ReLU -> MaxPool, followed by a final Dense\n",
    "# layer that feeds into a softmax probability output.\n",
    "@info(\"Constructing model...\")\n",
    "model = Chain(\n",
    "    # First convolution, operating upon a 28x28 image\n",
    "    Conv((3, 3), 1=>16, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "\n",
    "    # Second convolution, operating upon a 14x14 image\n",
    "    Conv((3, 3), 16=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "\n",
    "    # Third convolution, operating upon a 7x7 image\n",
    "    Conv((3, 3), 32=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "\n",
    "    # Reshape 3d tensor into a 2d one, at this point it should be (3, 3, 32, N)\n",
    "    # which is where we get the 288 in the `Dense` layer below:\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(288, 10),\n",
    "\n",
    "    # Finally, softmax to get nice probabilities\n",
    "    softmax,\n",
    ")\n",
    "\n",
    "@info(\"Loading model...\")\n",
    "# Load model and datasets onto GPU, if enabled\n",
    "# .... unfortunateley neither the current nor the commented-out\n",
    "#      code will actually make the GUP do anything.\n",
    "train_set =  train_set |> gpu # gpu.(train_set)\n",
    "test_set = test_set |> gpu # gpu.(test_set)\n",
    "model =  model |> gpu #gpu(model)\n",
    "\n",
    "@info(\"Precompiling model...\")\n",
    "# Make sure our model is nicely precompiled before starting our training loop\n",
    "model(train_set[1][1])\n",
    "\n",
    "@info(\"Done precompiling model...\")\n",
    "\n",
    "\n",
    "# `loss()` calculates the crossentropy loss between our prediction `y_hat`\n",
    "# (calculated from `model(x)`) and the ground truth `y`.  We augment the data\n",
    "# a bit, adding gaussian random noise to our image to make it more robust.\n",
    "function loss(x, y)\n",
    "    # We augment `x` a little bit here, adding in random noise\n",
    "    x_aug = x .+ 0.1f0*gpu(randn(eltype(x), size(x)))\n",
    "\n",
    "    y_hat = model(x_aug)\n",
    "    return crossentropy(y_hat, y)\n",
    "end\n",
    "accuracy(x, y) = mean(onecold(model(x)) .== onecold(y))\n",
    "\n",
    "# Train our model with the given training set using the ADAM optimizer and\n",
    "# printing out performance against the test set as we go.\n",
    "opt = ADAM(0.001)\n",
    "\n",
    "@info(\"Beginning training loop...\")\n",
    "best_acc = 0.0\n",
    "last_improvement = 0\n",
    "for epoch_idx in 1:100\n",
    "    \n",
    "    @info(@sprintf(\"[%d]:Starting epoch\", epoch_idx))\n",
    "    \n",
    "    global best_acc, last_improvement\n",
    "    # Train for a single epoch\n",
    "    Flux.train!(loss, params(model), train_set, opt)\n",
    "\n",
    "    # Calculate accuracy:\n",
    "    acc = accuracy(test_set...)\n",
    "    @info(@sprintf(\"[%d]: Test accuracy: %.4f\", epoch_idx, acc))\n",
    "\n",
    "    # If our accuracy is good enough, quit out.\n",
    "    if acc >= 0.999\n",
    "        @info(\" -> Early-exiting: We reached our target accuracy of 99.9%\")\n",
    "        break\n",
    "    end\n",
    "\n",
    "    # If this is the best accuracy we've seen so far, save the model out\n",
    "    if acc >= best_acc\n",
    "        @info(\" -> New best accuracy! Saving model out to mnist_conv.bson\")\n",
    "        BSON.@save joinpath(dirname(@__FILE__), \"mnist_conv.bson\") model epoch_idx acc\n",
    "        best_acc = acc\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    # If we haven't seen improvement in 5 epochs, drop our learning rate:\n",
    "    if epoch_idx - last_improvement >= 5 && opt.eta > 1e-6\n",
    "        opt.eta /= 10.0\n",
    "        @warn(\" -> Haven't improved in a while, dropping learning rate to $(opt.eta)!\")\n",
    "\n",
    "        # After dropping learning rate, give it a few epochs to improve\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    if epoch_idx - last_improvement >= 10\n",
    "        @warn(\" -> We're calling this converged.\")\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
